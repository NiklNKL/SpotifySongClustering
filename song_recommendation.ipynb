{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "- https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
    "- https://www.kaggle.com/datasets/tonygordonjr/spotify-dataset-2023?select=spotify-albums_data_2023.csv\n",
    "- https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "- https://github.com/jannine92/spotify_recommendation/blob/main/music_recommender.ipynb\n",
    "- https://www.kaggle.com/code/nyjoey/spotify-clustering\n",
    "- https://ausaf-a.github.io/ml-song-recommender/\n",
    "- https://medium.com/@Marlon_H/spotify-clustering-f41b40003c9a\n",
    "- https://www.kaggle.com/code/choongqianzheng/song-genre-classification-system\n",
    "- https://developer.spotify.com/documentation/web-api/reference/get-audio-features\n",
    "- https://medium.com/@miguelrodrigueznovelo/discover-your-perfect-playlist-10-songs-recommended-by-a-music-recommendation-system-with-python-5fd246d87127\n",
    "- https://medium.com/@shruti.somankar/building-a-music-recommendation-system-using-spotify-api-and-python-f7418a21fa41\n",
    "- https://www.kaggle.com/code/merveeyuboglu/music-recommendation-system-cosine-s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo List:\n",
    "\n",
    "- Basic stuff✅\n",
    "  - Load Data✅\n",
    "  -  Display, Info and Describe data✅\n",
    "  - Split Datasets into song_metrics and song_info✅\n",
    "- Data Visualization (Also in Percent if valuable)✅\n",
    "  - Visualize Correlation Heatmap✅\n",
    "  - Display Genres as Numbers and Histogram✅\n",
    "  - Display Genre Dendogram✅\n",
    "  - Display most frequent artists✅\n",
    "  - Display most popular artist✅\n",
    "  - Plot Popularity as histogram✅\n",
    "  - Plot Average Song metric for Each genre (could also be on a 3D plot)✅\n",
    "  - Plot Box plots to detect outliers✅\n",
    "- Features\n",
    "  - Apply Standard and MinMaxScaler ✅\n",
    "  - Apply and Visualize PCA and t-SNE / UMAP\n",
    "  - Use Silhouette Score to see how many clusters are needed (also try fancy plot from Medium)\n",
    "  - Use KMeans to start\n",
    "  - Use DBSCAN\n",
    "  - Use Agglomerative Clustering\n",
    "  - Use HDBSCAN\n",
    "  - Use XGBClassifier with Cross Validation\n",
    "- Feature Extensions\n",
    "  - Plot Similar Artists\n",
    "  - Plot Similar Genres\n",
    "  - (Plot Similar Songs [Only small set of Data here])\n",
    "- Possible Uses:\n",
    "  - Put song into spotify api, get song data back, and use that to find similar songs (with possibility to get different artists than the one from the provided song)\n",
    "  - Put Song in, get similar artist (you could also put multiple songs in, but I dont think that this is worth it)\n",
    "  - Simulate entering a whole user profile, from which we can take the average song data and get new artists this way (which are not in here)\n",
    "- Things missing\n",
    "  - We dont have the release date or listening date, so we cannot use time as a feature. This could create even better recommendations, because we would know what the user currently listens to and weigh it  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all Files in Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_concatenate_parquet_files(folder_path):\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "    \n",
    "    # Sort files for consistent order if needed (optional)\n",
    "    files.sort()\n",
    "\n",
    "    # Load and concatenate all the Parquet files\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_parquet(file_path)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    concatenated_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save File in Format for GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def save_dataframe_as_parquet(df:pd.DataFrame, folder_path=\"data\", folder_name=None, always_overwrite=None, model_object=None):\n",
    "    if not folder_name:\n",
    "        folder_name = input(\"Enter the name of the folder to save the files: \")\n",
    "\n",
    "    full_path = os.path.join(folder_path, folder_name)\n",
    "\n",
    "    # Check if the folder already exists\n",
    "    if os.path.exists(full_path) and always_overwrite is not True:\n",
    "        if always_overwrite is None:\n",
    "            overwrite = input(f\"The folder '{folder_name}' already exists. Do you want to overwrite it? (yes/no): \")\n",
    "            always_overwrite = overwrite.lower() != 'yes'\n",
    "        if not always_overwrite:\n",
    "            suffix = 1\n",
    "            new_folder_name = f\"{folder_name}_{suffix}\"\n",
    "            while os.path.exists(os.path.join(folder_path, new_folder_name)):\n",
    "                suffix += 1\n",
    "                new_folder_name = f\"{folder_name}_{suffix}\"\n",
    "            folder_name = new_folder_name\n",
    "            full_path = os.path.join(folder_path, folder_name)\n",
    "    \n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "    temp_file = os.path.join(full_path, \"temp.parquet\")\n",
    "    df.to_parquet(temp_file)\n",
    "    file_size = os.path.getsize(temp_file) / (1024 * 1024)  # Size in MB\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    if file_size > 50:\n",
    "        num_splits = math.ceil(file_size / 50)\n",
    "        row_split = math.ceil(len(df) / num_splits)\n",
    "    else:\n",
    "        num_splits = 1\n",
    "        row_split = len(df)\n",
    "    \n",
    "    for i in range(num_splits):\n",
    "        start_row = i * row_split\n",
    "        end_row = min((i + 1) * row_split, len(df))\n",
    "        split_df = df.iloc[start_row:end_row]\n",
    "        split_file_name = os.path.join(full_path, f\"{folder_name}_part_{i + 1}.parquet\")\n",
    "        split_df.to_parquet(split_file_name)\n",
    "    \n",
    "    if model_object:\n",
    "        for key, value in model_object.items():\n",
    "            joblib.dump(value, f'{full_path}/{key}_model.pkl')\n",
    "\n",
    "    print(f\"Dataframe saved in {num_splits} files under the folder: {full_path}\")\n",
    "    \n",
    "    return full_path\n",
    "\n",
    "# Example usage:\n",
    "# save_dataframe_as_parquet(df=kmeans_cluster, folder_path=\"data\", folder_name=\"kmeans_clustered_subset\", always_overwrite=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import hdbscan\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class MusicRecommendation:\n",
    "    def __init__(self,\n",
    "                 weight_year: float,\n",
    "                 weight_popularity: float,\n",
    "                 artist_name: str = None,\n",
    "                 song_name:str = None,\n",
    "                 recommendation_can_be_same_artist: bool  = None,\n",
    "                 number_of_recommendations: int = None,\n",
    "                 use_weighted_system: bool = None,\n",
    "                 filter_by_genre: str = None,\n",
    "                 filter_only_by_genre: bool = None,\n",
    "                 selected_cluster_algorithm: str = None,\n",
    "                 ):\n",
    "\n",
    "        # Initialize the Spotify client with authentication\n",
    "        load_dotenv()\n",
    "        auth_manager = SpotifyOAuth(client_id=os.getenv('SPOTIFY_CLIENT_ID'), client_secret=os.getenv('SPOTIFY_CLIENT_SECRET'), redirect_uri=os.getenv('SPOTIFY_REDIRECT_URI'), scope=\"user-library-read\")\n",
    "        self.sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "        \n",
    "        # Loading predefined_variables\n",
    "        self.original_data = load_and_concatenate_parquet_files(\"data/preprocessed_spotify_data\")\n",
    "        \n",
    "        self.kmeans_only_path = \"data/kmeans_clustered_subset\"\n",
    "        self.hdbscan_only_path = \"data/hdbscan_clustered_subset\"\n",
    "        self.kmeans_hdbscan_path = \"data/kmeans_hdbscan_clustered_subset\"\n",
    "        self.metrics = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','time_signature']\n",
    "        \n",
    "        # User input variables\n",
    "        self.weight_year = weight_year\n",
    "        self.weight_popularity = weight_popularity\n",
    "        self.use_weighted_system = use_weighted_system\n",
    "        self.artist_name = artist_name\n",
    "        self.song_name = song_name\n",
    "        self.only_recommend_new_artists = recommendation_can_be_same_artist\n",
    "        self.number_of_recommendations = number_of_recommendations\n",
    "        self.filter_by_genre = filter_by_genre\n",
    "        self.filter_only_by_genre = filter_only_by_genre\n",
    "        self.selected_cluster_algorithm = selected_cluster_algorithm\n",
    "        \n",
    "        self.clustered_data = None\n",
    "    \n",
    "    def get_user_input(self) -> None:\n",
    "        \"\"\" Get user input for the recommendation system \"\"\"\n",
    "        if self.artist_name == None:\n",
    "            while not self.artist_name or self.artist_name == \"\":\n",
    "                self.artist_name = input(\"Enter the artist name: \")\n",
    "                \n",
    "        if self.song_name == None:\n",
    "            while not self.song_name or self.song_name == \"\":\n",
    "                self.song_name = input(\"Enter the song name: \")\n",
    "                \n",
    "        if self.only_recommend_new_artists == None:\n",
    "            self.only_recommend_new_artists = input(\"Only recommend new artists? (yes/no): \").strip().lower() == 'yes'\n",
    "            \n",
    "        if self.number_of_recommendations == None:\n",
    "            self.number_of_recommendations = int(input(\"How many songs should be recommended (<=10): \"))\n",
    "            while self.number_of_recommendations > 10:\n",
    "                print(\"Invalid number\")\n",
    "                self.number_of_recommendations = int(input(\"How many songs should be recommended (<=10): \"))\n",
    "                \n",
    "        if self.use_weighted_system == None:\n",
    "            self.use_weighted_system = input(\"Should newer/more popular songs be preferred? (yes/no): \").strip().lower() == 'yes'\n",
    "            \n",
    "        if self.filter_by_genre == None:\n",
    "            self.filter_by_genre = input(\"Enter a genre you want to filter by: \")\n",
    "            \n",
    "        counter = 0\n",
    "        while self.filter_by_genre != \"\" and self.filter_by_genre not in self.original_data[\"genre\"].unique():\n",
    "            print(f\"Invalid genre. Tries remaining: {3 - counter}\")\n",
    "            print(\"Please select one of the following genres:\")\n",
    "            print(self.original_data[\"genre\"].unique())\n",
    "            self.filter_by_genre = input(\"Enter a genre you want to filter by: \")\n",
    "            counter += 1\n",
    "            if counter == 2:\n",
    "                print(\"Max tries reached. Not filtering by genre\")\n",
    "                self.filter_by_genre = \"\"\n",
    "                break \n",
    "        \n",
    "        if self.filter_only_by_genre == None and self.filter_by_genre != None and self.filter_by_genre != \"\":\n",
    "            self.filter_only_by_genre = input(\"Only filter by genre and not by cluster? (yes/no): \").strip().lower() == 'yes'\n",
    "            \n",
    "        if self.selected_cluster_algorithm == None and not self.filter_only_by_genre:\n",
    "            self.selected_cluster_algorithm = input(\"Which clustering algorithm to use? (kmeans/hdbscan/both): \").strip().lower()\n",
    "            while self.selected_cluster_algorithm not in [\"kmeans\", \"hdbscan\", \"both\"]:\n",
    "                print(\"Invalid choice\")\n",
    "                self.selected_cluster_algorithm = input(\"Which clustering algorithm to use? (kmeans/hdbscan/both): \").strip().lower()\n",
    "        \n",
    "        path = self.kmeans_only_path if self.selected_cluster_algorithm == \"kmeans\" else self.hdbscan_only_path if self.selected_cluster_algorithm == \"hdbscan\" else self.kmeans_hdbscan_path\n",
    "        self.clustered_data = load_and_concatenate_parquet_files(path)\n",
    "    \n",
    "    def fetch_spotify_data(self, song_name: str, artist_name: str) -> pd.DataFrame:\n",
    "        results = self.sp.search(q=f\"track:{song_name} artist:{artist_name}\", type=\"track\", limit=1)\n",
    "        \n",
    "        if not results['tracks']['items']:\n",
    "            print(\"Track not found\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if the track is not found\n",
    "        \n",
    "        track = results['tracks']['items'][0]\n",
    "        track_id = track['id']\n",
    "        track_name = track['name']\n",
    "        artist_name = track['artists'][0]['name']\n",
    "        popularity = track['popularity']\n",
    "        release_date = track['album']['release_date']\n",
    "        year = int(release_date.split('-')[0])\n",
    "        duration_ms = track['duration_ms']\n",
    "        audio_features = self.sp.audio_features(track_id)[0]\n",
    "        \n",
    "        data = {\n",
    "            'danceability': audio_features['danceability'],\n",
    "            'energy': audio_features['energy'],\n",
    "            'key': audio_features['key'],\n",
    "            'loudness': audio_features['loudness'],\n",
    "            'mode': audio_features['mode'],\n",
    "            'speechiness': audio_features['speechiness'],\n",
    "            'acousticness': audio_features['acousticness'],\n",
    "            'instrumentalness': audio_features['instrumentalness'],\n",
    "            'liveness': audio_features['liveness'],\n",
    "            'valence': audio_features['valence'],\n",
    "            'tempo': audio_features['tempo'],\n",
    "            'time_signature': audio_features['time_signature'],\n",
    "            'artist_name': artist_name,\n",
    "            'track_name': track_name,\n",
    "            'track_id': track_id,\n",
    "            'popularity': popularity,\n",
    "            'year': year,\n",
    "            'duration_ms': duration_ms\n",
    "        }\n",
    "        \n",
    "        song = pd.DataFrame([data])\n",
    "        \n",
    "        self.artist_name = song[\"artist_name\"].values[0]\n",
    "        self.song_name = song[\"track_name\"].values[0]\n",
    "        print(\"Song found on Spotify\")\n",
    "        self.print_preview_urls(song)\n",
    "        return song\n",
    "    \n",
    "    def prepare_song_data(self, song: pd.DataFrame) -> pd.DataFrame:\n",
    "        clustered_data = self.remove_song_from_clustered_data_if_present(song, self.clustered_data)\n",
    "        \n",
    "        all_songs = pd.concat([clustered_data, song], ignore_index=True) \n",
    "        all_song_standardized = self.normalize_data(all_songs, self.metrics)\n",
    "        \n",
    "        song_standardized = all_song_standardized[(all_song_standardized[\"track_name\"] == self.song_name) & (all_song_standardized[\"artist_name\"] == self.artist_name)]\n",
    "        all_song_standardized = all_song_standardized.drop(song_standardized.index)\n",
    "        \n",
    "        return song_standardized, all_song_standardized\n",
    "    \n",
    "    def normalize_data(self, data: pd.DataFrame, metric_columns:list[str]) -> pd.DataFrame:\n",
    "        numeric_columns = data[metric_columns].copy()\n",
    "        other_columns = data.drop(columns=metric_columns).reset_index(drop=True).copy()\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        normalized_data = min_max_scaler.fit_transform(numeric_columns)\n",
    "        return pd.merge(pd.DataFrame(normalized_data, columns=metric_columns), other_columns, left_index=True, right_index=True)\n",
    "    \n",
    "    def remove_song_from_clustered_data_if_present(self, song: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        matched_rows = data[(data[\"track_name\"] == song[\"track_name\"].values[0]) & (data[\"artist_name\"] == song[\"artist_name\"].values[0])]\n",
    "        if not matched_rows.empty:\n",
    "            print(f\"Removing {len(matched_rows)} rows from possible recommendations\")\n",
    "            if len(matched_rows) > 1:\n",
    "                print(\"Rows to be removed:\")\n",
    "                display(matched_rows.head(5))\n",
    "            indexes_to_remove = matched_rows.index\n",
    "            return data.drop(indexes_to_remove)\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "    def filter_possible_recommendations(self, data, kmeans_cluster=None, hdbscan_cluster=None) -> pd.DataFrame:\n",
    "        if self.filter_by_genre != \"\":\n",
    "            data = data[data[\"genre\"] == self.filter_by_genre]\n",
    "        if self.filter_only_by_genre:\n",
    "            return data\n",
    "        \n",
    "        if kmeans_cluster is not None:\n",
    "            data = data[data[\"kmeans_cluster\"] == kmeans_cluster]\n",
    "        if hdbscan_cluster is not None:\n",
    "            data = data[data[\"hdbscan_cluster\"] == hdbscan_cluster]     \n",
    "        if not self.only_recommend_new_artists:\n",
    "            data = data[data[\"artist_name\"] != self.artist_name]\n",
    "        return data\n",
    "\n",
    "    def get_song_cluster(self, song: pd.DataFrame, selected_clustering_method: str | None) -> int:\n",
    "        kmeans_cluster = None\n",
    "        hdbscan_cluster = None\n",
    "        if selected_clustering_method is None or self.filter_only_by_genre:\n",
    "            return kmeans_cluster, hdbscan_cluster\n",
    "        \n",
    "        if selected_clustering_method == \"hdbscan\":\n",
    "            hdbscan_cluster = self.use_hdbscan(song, self.hdbscan_only_path)\n",
    "            print(f\"Predicted HDBSCAN cluster: {hdbscan_cluster}\")\n",
    "            \n",
    "        elif selected_clustering_method == \"kmeans\":\n",
    "            kmeans_cluster = self.use_kmeans(song, self.kmeans_only_path)\n",
    "            print(f\"Predicted KMeans cluster: {kmeans_cluster}\")\n",
    "            \n",
    "        elif selected_clustering_method == \"both\":\n",
    "            kmeans_cluster = self.use_kmeans(song, self.kmeans_hdbscan_path)\n",
    "            hdbscan_cluster = self.use_hdbscan(song, self.kmeans_hdbscan_path, number=kmeans_cluster)\n",
    "            print(f\"Predicted KMeans cluster: {kmeans_cluster}, HDBSCAN cluster: {hdbscan_cluster}\")\n",
    "        return kmeans_cluster, hdbscan_cluster\n",
    "    \n",
    "    def use_kmeans(self, song: pd.DataFrame, path) -> int:\n",
    "        kmeans_model = joblib.load(f\"{path}/kmeans_model.pkl\")\n",
    "        kmeans_cluster = kmeans_model.predict(song[self.metrics])[0]\n",
    "        return kmeans_cluster\n",
    "    \n",
    "    def use_hdbscan(self, song: pd.DataFrame, path, number=None) -> int:\n",
    "        hdbscan_model = joblib.load(f\"{path}/hdbscan_model{f'_{number}' if number is not None else ''}.pkl\")\n",
    "        new_data_point = song[self.metrics].values.reshape(1, -1)\n",
    "        predicted_cluster, _ = hdbscan.approximate_predict(hdbscan_model, new_data_point)\n",
    "        hdbscan_cluster = predicted_cluster[0]\n",
    "        return hdbscan_cluster\n",
    "\n",
    "    def find_nearest_neighbors(self, song: pd.DataFrame, possible_recommendations: pd.DataFrame) -> tuple:\n",
    "        number_of_neighbors = 100 if len(possible_recommendations) > 100 else len(possible_recommendations)\n",
    "        knn_model = NearestNeighbors(n_neighbors=number_of_neighbors)\n",
    "        cluster_data = possible_recommendations[self.metrics]\n",
    "        knn_model.fit(cluster_data)\n",
    "        distances, indices = knn_model.kneighbors(song[self.metrics], n_neighbors=number_of_neighbors)\n",
    "        neighbors_df = possible_recommendations.iloc[indices[0]].copy()\n",
    "        neighbors_df[\"distance\"] = distances[0]\n",
    "        return neighbors_df, distances[0]\n",
    "\n",
    "    def get_weighted_scores(self, neighbors_df: pd.DataFrame, neighbor_distances: np.ndarray) -> pd.DataFrame:\n",
    "        neighbors_df = neighbors_df.copy()\n",
    "        scaler = MinMaxScaler()\n",
    "        neighbors_df[['year_normalized', 'popularity_normalized']] = scaler.fit_transform(\n",
    "            neighbors_df[['year', 'popularity']]\n",
    "        )\n",
    "        \n",
    "        year_normalized = neighbors_df['year_normalized'].values\n",
    "        popularity_normalized = neighbors_df['popularity_normalized'].values\n",
    "\n",
    "        base_scores = 1 / (neighbor_distances + 1e-8)  # Avoid division by zero\n",
    "        boosting_scores = year_normalized * self.weight_year + popularity_normalized * self.weight_popularity\n",
    "        final_scores = base_scores + boosting_scores\n",
    "        neighbors_df[\"weighted_score\"] = final_scores\n",
    "   \n",
    "        ranked_indices = np.argsort(final_scores)[::-1]  # Sort in descending order\n",
    "        \n",
    "        new_order_df = neighbors_df.iloc[ranked_indices].copy()\n",
    "        \n",
    "        new_order_df = new_order_df.drop(columns=['year_normalized', 'popularity_normalized'])\n",
    "        return new_order_df\n",
    "\n",
    "    def print_preview_urls(self, song_df: pd.DataFrame) -> None:\n",
    "        for _, row in song_df.iterrows():\n",
    "            track_id = row['track_id']\n",
    "            track = self.sp.track(track_id)\n",
    "            preview_url = track.get('preview_url')\n",
    "            if preview_url:\n",
    "                print(f\"Track: {row['track_name']} by {row['artist_name']}\")\n",
    "                print(f\"Preview URL: {preview_url}\")\n",
    "            else:\n",
    "                print(f\"Track: {row['track_name']} by {row['artist_name']}\")\n",
    "                print(\"Preview URL not available.\")\n",
    "    \n",
    "    def prepare_results(self, neighbors_df: pd.DataFrame,song_standardized, all_song_standardized) -> pd.DataFrame:\n",
    "        closest_songs = neighbors_df.head(self.number_of_recommendations)\n",
    "        self.plot_pca_scatter(possible_recommendations=all_song_standardized, recommended_songs=closest_songs, user_selected_song=song_standardized)\n",
    "        closest_songs = closest_songs.drop(columns=[\"artist_name\", \"track_name\", \"year\", \"popularity\", \"duration_ms\", \"genre\"] + self.metrics)\n",
    "        original_selected_songs = self.original_data[self.original_data[\"track_id\"].isin(closest_songs[\"track_id\"])].copy()\n",
    "        songs_to_recommend = pd.merge(original_selected_songs, closest_songs, on=\"track_id\")\n",
    "        print(\"\\nRecommended songs:\")\n",
    "        sort_value = \"weighted_score\" if self.use_weighted_system else \"distance\"\n",
    "        songs_to_recommend = songs_to_recommend.sort_values(by=sort_value, ascending=sort_value == \"distance\")\n",
    "        self.print_preview_urls(songs_to_recommend)\n",
    "        return songs_to_recommend\n",
    "\n",
    "    def plot_pca_scatter(self, possible_recommendations: pd.DataFrame, recommended_songs:pd.DataFrame, user_selected_song:pd.DataFrame, n_components=2, circle_opacity=0.5):\n",
    "        def prepare_pca_df(data, pca, source_label):\n",
    "            \"\"\"Apply PCA and add relevant columns to the resulting DataFrame.\"\"\"\n",
    "            pca_transformed = pca.transform(data[self.metrics])\n",
    "            pca_df = pd.DataFrame(pca_transformed, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "            pca_df['source'] = source_label\n",
    "            pca_df = pd.concat([pca_df, data[['genre', 'danceability', 'energy', 'valence', 'artist_name', 'track_name']].reset_index(drop=True)], axis=1)\n",
    "            return pca_df\n",
    "        \n",
    "        sample_size = 100000 if len(possible_recommendations) > 100000 else len(possible_recommendations)\n",
    "        possible_recommendations = possible_recommendations.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(possible_recommendations[self.metrics])\n",
    "\n",
    "        possible_recommendations_pca = prepare_pca_df(possible_recommendations, pca, 'all_songs')\n",
    "        recommended_songs_pca = prepare_pca_df(recommended_songs, pca, 'recommended_songs')\n",
    "        user_selected_song_pca = prepare_pca_df(user_selected_song, pca, 'user_selected_song')\n",
    "   \n",
    "        df_combined = pd.concat([possible_recommendations_pca, recommended_songs_pca, user_selected_song_pca], ignore_index=True)\n",
    "\n",
    "        df_combined['danceability'] = df_combined['danceability'].round(4)\n",
    "        df_combined['energy'] = df_combined['energy'].round(4)\n",
    "        df_combined['valence'] = df_combined['valence'].round(4)\n",
    "        df_combined[\"genre\"] = df_combined[\"genre\"].fillna(\"Unknown\")\n",
    "        \n",
    "        df_combined = df_combined[~((df_combined['source'] == 'all_songs') &\n",
    "          (df_combined['track_name'].isin(recommended_songs_pca[\"track_name\"].unique())) & df_combined['artist_name'].isin(recommended_songs_pca[\"artist_name\"].unique()))\n",
    "                ]\n",
    "        \n",
    "        marker_shapes = {'all_songs': 'circle', 'recommended_songs': 'triangle-up', 'user_selected_song': 'cross'}\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            df_combined, \n",
    "            x='PC1', y='PC2', \n",
    "            color='source', symbol='source',\n",
    "            hover_data={'PC1': False, 'PC2': False, 'genre': True, 'artist_name': True, 'track_name': True, \n",
    "                        'danceability': True, 'energy': True, 'valence': True},\n",
    "            symbol_map=marker_shapes, \n",
    "            title='PCA Scatter Plot',\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=8))\n",
    "        fig.for_each_trace(\n",
    "            lambda trace: trace.update(marker=dict(opacity=circle_opacity)) if trace.name == 'all_songs' else ()\n",
    "        )\n",
    "        fig.for_each_trace(\n",
    "            lambda trace: trace.update(marker=dict(size=16)) if trace.name != 'all_songs' else ()\n",
    "        )\n",
    "\n",
    "        hover_template = (\n",
    "            \"<b>%{customdata[2]}</b><br>\"  # Track name\n",
    "            \"Artist: %{customdata[1]}<br>\"\n",
    "            \"Genre: %{customdata[0]}<br>\"\n",
    "            \"Danceability: %{customdata[3]:.4f}<br>\"\n",
    "            \"Energy: %{customdata[4]:.4f}<br>\"\n",
    "            \"Valence: %{customdata[5]:.4f}<extra></extra>\"\n",
    "        )\n",
    "\n",
    "        fig.update_traces(hovertemplate=hover_template)\n",
    "        fig.show()\n",
    "    \n",
    "    def recommend_songs(self) -> pd.DataFrame:\n",
    "        self.get_user_input()\n",
    "        song = self.fetch_spotify_data(self.song_name, self.artist_name)\n",
    "        \n",
    "        if song.empty:\n",
    "            print(\"No match found. Please try again.\")\n",
    "            return None\n",
    "        \n",
    "        song_standardized, all_song_standardized = self.prepare_song_data(song)\n",
    "        \n",
    "        kmeans_cluster, hdbscan_cluster = self.get_song_cluster(song_standardized, self.selected_cluster_algorithm)\n",
    "        \n",
    "        possible_recommendations = self.filter_possible_recommendations(data=all_song_standardized, kmeans_cluster=kmeans_cluster, hdbscan_cluster=hdbscan_cluster)\n",
    "        \n",
    "        neighbors_df, neighbor_distances = self.find_nearest_neighbors(song_standardized, possible_recommendations)\n",
    "        \n",
    "        if self.use_weighted_system:\n",
    "            neighbors_df = self.get_weighted_scores(neighbors_df, neighbor_distances)\n",
    "            \n",
    "        songs_to_recommend = self.prepare_results(neighbors_df=neighbors_df, song_standardized=song_standardized, all_song_standardized=all_song_standardized)\n",
    "        \n",
    "        return songs_to_recommend\n",
    "\n",
    "\n",
    "recommended_songs_df = MusicRecommendation(weight_year=0.6,\n",
    "                                weight_popularity=0.4,\n",
    "                                artist_name=\"Dorfterror\",\n",
    "                                song_name=\"No Future Kid\",\n",
    "                                # filter_by_genre=\"\",\n",
    "                                # filter_only_by_genre=\"no\",\n",
    "                                selected_cluster_algorithm=\"hdbscan\",\n",
    "                                use_weighted_system=\"yes\",\n",
    "                                number_of_recommendations=5,\n",
    "                                recommendation_can_be_same_artist=\"no\"\n",
    "                                ).recommend_songs()\n",
    "display(recommended_songs_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
