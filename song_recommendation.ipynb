{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "- https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
    "- https://www.kaggle.com/datasets/tonygordonjr/spotify-dataset-2023?select=spotify-albums_data_2023.csv\n",
    "- https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "- https://github.com/jannine92/spotify_recommendation/blob/main/music_recommender.ipynb\n",
    "- https://www.kaggle.com/code/nyjoey/spotify-clustering\n",
    "- https://ausaf-a.github.io/ml-song-recommender/\n",
    "- https://medium.com/@Marlon_H/spotify-clustering-f41b40003c9a\n",
    "- https://www.kaggle.com/code/choongqianzheng/song-genre-classification-system\n",
    "- https://developer.spotify.com/documentation/web-api/reference/get-audio-features\n",
    "- https://medium.com/@miguelrodrigueznovelo/discover-your-perfect-playlist-10-songs-recommended-by-a-music-recommendation-system-with-python-5fd246d87127\n",
    "- https://medium.com/@shruti.somankar/building-a-music-recommendation-system-using-spotify-api-and-python-f7418a21fa41\n",
    "- https://www.kaggle.com/code/merveeyuboglu/music-recommendation-system-cosine-s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo List:\n",
    "\n",
    "- Basic stuff✅\n",
    "  - Load Data✅\n",
    "  -  Display, Info and Describe data✅\n",
    "  - Split Datasets into song_metrics and song_info✅\n",
    "- Data Visualization (Also in Percent if valuable)✅\n",
    "  - Visualize Correlation Heatmap✅\n",
    "  - Display Genres as Numbers and Histogram✅\n",
    "  - Display Genre Dendogram✅\n",
    "  - Display most frequent artists✅\n",
    "  - Display most popular artist✅\n",
    "  - Plot Popularity as histogram✅\n",
    "  - Plot Average Song metric for Each genre (could also be on a 3D plot)✅\n",
    "  - Plot Box plots to detect outliers✅\n",
    "- Features\n",
    "  - Apply Standard and MinMaxScaler ✅\n",
    "  - Apply and Visualize PCA and t-SNE / UMAP\n",
    "  - Use Silhouette Score to see how many clusters are needed (also try fancy plot from Medium)\n",
    "  - Use KMeans to start\n",
    "  - Use DBSCAN\n",
    "  - Use Agglomerative Clustering\n",
    "  - Use HDBSCAN\n",
    "  - Use XGBClassifier with Cross Validation\n",
    "- Feature Extensions\n",
    "  - Plot Similar Artists\n",
    "  - Plot Similar Genres\n",
    "  - (Plot Similar Songs [Only small set of Data here])\n",
    "- Possible Uses:\n",
    "  - Put song into spotify api, get song data back, and use that to find similar songs (with possibility to get different artists than the one from the provided song)\n",
    "  - Put Song in, get similar artist (you could also put multiple songs in, but I dont think that this is worth it)\n",
    "  - Simulate entering a whole user profile, from which we can take the average song data and get new artists this way (which are not in here)\n",
    "- Things missing\n",
    "  - We dont have the release date or listening date, so we cannot use time as a feature. This could create even better recommendations, because we would know what the user currently listens to and weigh it  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>I Won't Give Up</td>\n",
       "      <td>53QF56cjZA9RTuuMZDrSA6</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.139</td>\n",
       "      <td>133.406</td>\n",
       "      <td>240166.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>93 Million Miles</td>\n",
       "      <td>1s8tP3jP4GZcyHDsjvw218</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.454</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.515</td>\n",
       "      <td>140.182</td>\n",
       "      <td>216387.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joshua Hyslop</td>\n",
       "      <td>Do Not Let Me Go</td>\n",
       "      <td>7BRCa8MPiyuvr2VU3O9W0F</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.234</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-13.711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.3380</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.145</td>\n",
       "      <td>139.832</td>\n",
       "      <td>158960.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boyce Avenue</td>\n",
       "      <td>Fast Car</td>\n",
       "      <td>63wsZUhUZLlh1OsyrZq7sz</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.251</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9.845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.508</td>\n",
       "      <td>204.961</td>\n",
       "      <td>304293.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrew Belle</td>\n",
       "      <td>Sky's Still Blue</td>\n",
       "      <td>6nXIYClvJAfi6ujLiKqEq8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.791</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.217</td>\n",
       "      <td>171.864</td>\n",
       "      <td>244320.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     artist_name        track_name                track_id  popularity  \\\n",
       "0     Jason Mraz   I Won't Give Up  53QF56cjZA9RTuuMZDrSA6        68.0   \n",
       "1     Jason Mraz  93 Million Miles  1s8tP3jP4GZcyHDsjvw218        50.0   \n",
       "2  Joshua Hyslop  Do Not Let Me Go  7BRCa8MPiyuvr2VU3O9W0F        57.0   \n",
       "3   Boyce Avenue          Fast Car  63wsZUhUZLlh1OsyrZq7sz        58.0   \n",
       "4   Andrew Belle  Sky's Still Blue  6nXIYClvJAfi6ujLiKqEq8        54.0   \n",
       "\n",
       "        year     genre  danceability  energy   key  loudness  mode  \\\n",
       "0 2012-01-01  acoustic         0.483   0.303   4.0   -10.058   1.0   \n",
       "1 2012-01-01  acoustic         0.572   0.454   3.0   -10.286   1.0   \n",
       "2 2012-01-01  acoustic         0.409   0.234   3.0   -13.711   1.0   \n",
       "3 2012-01-01  acoustic         0.392   0.251  10.0    -9.845   1.0   \n",
       "4 2012-01-01  acoustic         0.430   0.791   6.0    -5.419   0.0   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0429        0.6940          0.000000    0.1150    0.139  133.406   \n",
       "1       0.0258        0.4770          0.000014    0.0974    0.515  140.182   \n",
       "2       0.0323        0.3380          0.000050    0.0895    0.145  139.832   \n",
       "3       0.0363        0.8070          0.000000    0.0797    0.508  204.961   \n",
       "4       0.0302        0.0726          0.019300    0.1100    0.217  171.864   \n",
       "\n",
       "   duration_ms  time_signature  \n",
       "0     240166.0             3.0  \n",
       "1     216387.0             4.0  \n",
       "2     158960.0             4.0  \n",
       "3     304293.0             4.0  \n",
       "4     244320.0             4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2013313</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "      <td>2.013313e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.848877e+01</td>\n",
       "      <td>2005-10-05 01:00:34.158026624</td>\n",
       "      <td>5.491744e-01</td>\n",
       "      <td>5.904303e-01</td>\n",
       "      <td>5.256363e+00</td>\n",
       "      <td>-9.799186e+00</td>\n",
       "      <td>6.422682e-01</td>\n",
       "      <td>1.010894e-01</td>\n",
       "      <td>3.714914e-01</td>\n",
       "      <td>2.211444e-01</td>\n",
       "      <td>2.162194e-01</td>\n",
       "      <td>4.809441e-01</td>\n",
       "      <td>1.200666e+02</td>\n",
       "      <td>2.385117e+05</td>\n",
       "      <td>3.878141e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1886-01-01 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.073000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2002-01-01 00:00:00</td>\n",
       "      <td>4.280000e-01</td>\n",
       "      <td>3.870000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-1.217600e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.600000e-02</td>\n",
       "      <td>2.060000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.790000e-02</td>\n",
       "      <td>2.540000e-01</td>\n",
       "      <td>9.700300e+01</td>\n",
       "      <td>1.751250e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>5.650000e-01</td>\n",
       "      <td>6.220000e-01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>-8.334000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.870000e-02</td>\n",
       "      <td>2.490000e-01</td>\n",
       "      <td>4.380000e-04</td>\n",
       "      <td>1.330000e-01</td>\n",
       "      <td>4.740000e-01</td>\n",
       "      <td>1.200100e+02</td>\n",
       "      <td>2.185470e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>6.860000e-01</td>\n",
       "      <td>8.250000e-01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-5.815000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.800000e-02</td>\n",
       "      <td>7.210000e-01</td>\n",
       "      <td>4.240000e-01</td>\n",
       "      <td>2.790000e-01</td>\n",
       "      <td>7.020000e-01</td>\n",
       "      <td>1.382540e+02</td>\n",
       "      <td>2.739870e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>9.990000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>6.172000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.710000e-01</td>\n",
       "      <td>9.960000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.499930e+02</td>\n",
       "      <td>6.000495e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.674866e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.819063e-01</td>\n",
       "      <td>2.708000e-01</td>\n",
       "      <td>3.549231e+00</td>\n",
       "      <td>5.787686e+00</td>\n",
       "      <td>4.793327e-01</td>\n",
       "      <td>1.522333e-01</td>\n",
       "      <td>3.599918e-01</td>\n",
       "      <td>3.519784e-01</td>\n",
       "      <td>1.926347e-01</td>\n",
       "      <td>2.695143e-01</td>\n",
       "      <td>2.996391e+01</td>\n",
       "      <td>1.405136e+05</td>\n",
       "      <td>4.832763e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         popularity                           year  danceability  \\\n",
       "count  2.013313e+06                        2013313  2.013313e+06   \n",
       "mean   1.848877e+01  2005-10-05 01:00:34.158026624  5.491744e-01   \n",
       "min    0.000000e+00            1886-01-01 00:00:00  0.000000e+00   \n",
       "25%    3.000000e+00            2002-01-01 00:00:00  4.280000e-01   \n",
       "50%    1.500000e+01            2011-01-01 00:00:00  5.650000e-01   \n",
       "75%    3.000000e+01            2018-01-01 00:00:00  6.860000e-01   \n",
       "max    1.000000e+02            2023-01-01 00:00:00  9.990000e-01   \n",
       "std    1.674866e+01                            NaN  1.819063e-01   \n",
       "\n",
       "             energy           key      loudness          mode   speechiness  \\\n",
       "count  2.013313e+06  2.013313e+06  2.013313e+06  2.013313e+06  2.013313e+06   \n",
       "mean   5.904303e-01  5.256363e+00 -9.799186e+00  6.422682e-01  1.010894e-01   \n",
       "min    0.000000e+00  0.000000e+00 -6.000000e+01  0.000000e+00  0.000000e+00   \n",
       "25%    3.870000e-01  2.000000e+00 -1.217600e+01  0.000000e+00  3.600000e-02   \n",
       "50%    6.220000e-01  5.000000e+00 -8.334000e+00  1.000000e+00  4.870000e-02   \n",
       "75%    8.250000e-01  8.000000e+00 -5.815000e+00  1.000000e+00  8.800000e-02   \n",
       "max    1.000000e+00  1.100000e+01  6.172000e+00  1.000000e+00  9.710000e-01   \n",
       "std    2.708000e-01  3.549231e+00  5.787686e+00  4.793327e-01  1.522333e-01   \n",
       "\n",
       "       acousticness  instrumentalness      liveness       valence  \\\n",
       "count  2.013313e+06      2.013313e+06  2.013313e+06  2.013313e+06   \n",
       "mean   3.714914e-01      2.211444e-01  2.162194e-01  4.809441e-01   \n",
       "min    0.000000e+00      0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.060000e-02      0.000000e+00  9.790000e-02  2.540000e-01   \n",
       "50%    2.490000e-01      4.380000e-04  1.330000e-01  4.740000e-01   \n",
       "75%    7.210000e-01      4.240000e-01  2.790000e-01  7.020000e-01   \n",
       "max    9.960000e-01      1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "std    3.599918e-01      3.519784e-01  1.926347e-01  2.695143e-01   \n",
       "\n",
       "              tempo   duration_ms  time_signature  \n",
       "count  2.013313e+06  2.013313e+06    2.013313e+06  \n",
       "mean   1.200666e+02  2.385117e+05    3.878141e+00  \n",
       "min    0.000000e+00  2.073000e+03    0.000000e+00  \n",
       "25%    9.700300e+01  1.751250e+05    4.000000e+00  \n",
       "50%    1.200100e+02  2.185470e+05    4.000000e+00  \n",
       "75%    1.382540e+02  2.739870e+05    4.000000e+00  \n",
       "max    2.499930e+02  6.000495e+06    5.000000e+00  \n",
       "std    2.996391e+01  1.405136e+05    4.832763e-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2013313 entries, 0 to 2013312\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   artist_name       object        \n",
      " 1   track_name        object        \n",
      " 2   track_id          object        \n",
      " 3   popularity        float64       \n",
      " 4   year              datetime64[ns]\n",
      " 5   genre             object        \n",
      " 6   danceability      float64       \n",
      " 7   energy            float64       \n",
      " 8   key               float64       \n",
      " 9   loudness          float64       \n",
      " 10  mode              float64       \n",
      " 11  speechiness       float64       \n",
      " 12  acousticness      float64       \n",
      " 13  instrumentalness  float64       \n",
      " 14  liveness          float64       \n",
      " 15  valence           float64       \n",
      " 16  tempo             float64       \n",
      " 17  duration_ms       float64       \n",
      " 18  time_signature    float64       \n",
      "dtypes: datetime64[ns](1), float64(14), object(4)\n",
      "memory usage: 291.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for i in range(3):\n",
    "    data = pd.read_parquet(f'spotify_data_part_{i+1}.parquet')\n",
    "    results.append(data)\n",
    "\n",
    "original_data = pd.concat(results)\n",
    "\n",
    "\n",
    "original_data[\"year\"] = pd.to_datetime(original_data[\"year\"], format='%Y')\n",
    "original_data = original_data.dropna(subset=[\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"duration_ms\", \"time_signature\", \"popularity\", \"track_id\", \"track_name\", \"artist_name\", \"year\"])\n",
    "original_data = original_data.drop_duplicates(subset=[\"track_name\", \"artist_name\", \"danceability\", \"energy\", \"key\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"time_signature\"])\n",
    "original_data = original_data.reset_index(drop=True)\n",
    "original_data = original_data.drop(columns=[\"Unnamed: 0\"])\n",
    "display(original_data.head())\n",
    "display(original_data.describe())\n",
    "print(original_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engine code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.064824</td>\n",
       "      <td>1.317150</td>\n",
       "      <td>-1.477662</td>\n",
       "      <td>0.887697</td>\n",
       "      <td>-1.344018</td>\n",
       "      <td>-0.254815</td>\n",
       "      <td>-0.454620</td>\n",
       "      <td>-0.624436</td>\n",
       "      <td>0.406616</td>\n",
       "      <td>1.397004</td>\n",
       "      <td>1.463675</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Santana</td>\n",
       "      <td>Brown Skin Girl (feat. Bo Bice)</td>\n",
       "      <td>14kZ72wYjQckHYuEvleiUx</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>blues</td>\n",
       "      <td>282707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620469</td>\n",
       "      <td>-1.099396</td>\n",
       "      <td>-1.197239</td>\n",
       "      <td>-0.891436</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>5.574823</td>\n",
       "      <td>1.006105</td>\n",
       "      <td>-0.624436</td>\n",
       "      <td>2.588485</td>\n",
       "      <td>0.160478</td>\n",
       "      <td>-1.153218</td>\n",
       "      <td>-1.818338</td>\n",
       "      <td>Steve Hofstetter</td>\n",
       "      <td>The Reason You Take a Date to See Me</td>\n",
       "      <td>3SqfXryD4Ws7WYLEdOEYRq</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>comedy</td>\n",
       "      <td>262360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.007327</td>\n",
       "      <td>-0.285246</td>\n",
       "      <td>-1.477662</td>\n",
       "      <td>0.630475</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>-0.439033</td>\n",
       "      <td>1.075663</td>\n",
       "      <td>-0.623538</td>\n",
       "      <td>-0.478482</td>\n",
       "      <td>0.873430</td>\n",
       "      <td>1.197960</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Jack Hartmann</td>\n",
       "      <td>We Are a Family</td>\n",
       "      <td>5hnzpC8Fp3BzDgaacxGItd</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>party</td>\n",
       "      <td>194320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.134438</td>\n",
       "      <td>0.373476</td>\n",
       "      <td>-1.477662</td>\n",
       "      <td>0.767010</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>-0.426621</td>\n",
       "      <td>-0.707812</td>\n",
       "      <td>-0.620788</td>\n",
       "      <td>-0.845386</td>\n",
       "      <td>1.014535</td>\n",
       "      <td>-0.579823</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Tina Moore</td>\n",
       "      <td>Never Gonna Let You Go - Kelly G. Bump-N-Go Vo...</td>\n",
       "      <td>0bwYKV0xuWcYviq9XJbCex</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>garage</td>\n",
       "      <td>253080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128605</td>\n",
       "      <td>-1.084593</td>\n",
       "      <td>-1.197239</td>\n",
       "      <td>-0.571346</td>\n",
       "      <td>-1.344018</td>\n",
       "      <td>-0.325367</td>\n",
       "      <td>0.789083</td>\n",
       "      <td>-0.624436</td>\n",
       "      <td>-0.715709</td>\n",
       "      <td>-0.493061</td>\n",
       "      <td>-0.172513</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>The American Young Voices Choir</td>\n",
       "      <td>Pop Medley From Trolls</td>\n",
       "      <td>3wYVbfMrSb1upgotmkIq93</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>392972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40261</th>\n",
       "      <td>0.614942</td>\n",
       "      <td>0.432687</td>\n",
       "      <td>-0.355971</td>\n",
       "      <td>0.164445</td>\n",
       "      <td>-1.344018</td>\n",
       "      <td>0.244271</td>\n",
       "      <td>-0.635472</td>\n",
       "      <td>-0.622860</td>\n",
       "      <td>-0.571109</td>\n",
       "      <td>-0.418795</td>\n",
       "      <td>-0.679688</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Phabo</td>\n",
       "      <td>Step 2 Me</td>\n",
       "      <td>57tg0m3Iu8YzWyaDfFfDtR</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>chill</td>\n",
       "      <td>110400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40262</th>\n",
       "      <td>0.686787</td>\n",
       "      <td>1.331953</td>\n",
       "      <td>0.485297</td>\n",
       "      <td>1.292600</td>\n",
       "      <td>-1.344018</td>\n",
       "      <td>-0.361949</td>\n",
       "      <td>-0.867518</td>\n",
       "      <td>-0.624425</td>\n",
       "      <td>0.401470</td>\n",
       "      <td>0.528094</td>\n",
       "      <td>0.257683</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Sick Individuals</td>\n",
       "      <td>I Want You</td>\n",
       "      <td>0oZDidA985NcUVE2GhnHI1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>edm</td>\n",
       "      <td>186576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40263</th>\n",
       "      <td>0.460198</td>\n",
       "      <td>-0.081708</td>\n",
       "      <td>1.046143</td>\n",
       "      <td>-0.352959</td>\n",
       "      <td>-1.344018</td>\n",
       "      <td>-0.478881</td>\n",
       "      <td>0.271569</td>\n",
       "      <td>-0.424952</td>\n",
       "      <td>-0.478482</td>\n",
       "      <td>0.609786</td>\n",
       "      <td>-0.475782</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>Marshmellow</td>\n",
       "      <td>A Lighthouse For Your Soul</td>\n",
       "      <td>7k74WfhigDSzIFQ9AGXiPB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>218350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40264</th>\n",
       "      <td>-0.888280</td>\n",
       "      <td>1.376361</td>\n",
       "      <td>1.606988</td>\n",
       "      <td>1.690014</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>1.452791</td>\n",
       "      <td>-0.387844</td>\n",
       "      <td>0.709253</td>\n",
       "      <td>0.036109</td>\n",
       "      <td>-0.972076</td>\n",
       "      <td>0.162863</td>\n",
       "      <td>0.252343</td>\n",
       "      <td>MC5</td>\n",
       "      <td>I’m A Man (Live 1966)</td>\n",
       "      <td>0eg53He31OMpYqNWmVwFAq</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>garage</td>\n",
       "      <td>256679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40265</th>\n",
       "      <td>-0.401944</td>\n",
       "      <td>-0.107613</td>\n",
       "      <td>-0.916817</td>\n",
       "      <td>0.167406</td>\n",
       "      <td>0.744038</td>\n",
       "      <td>-0.431194</td>\n",
       "      <td>1.220345</td>\n",
       "      <td>-0.623923</td>\n",
       "      <td>-0.682775</td>\n",
       "      <td>0.357282</td>\n",
       "      <td>-1.246534</td>\n",
       "      <td>-1.818338</td>\n",
       "      <td>Eli Silva e Zé Goiano</td>\n",
       "      <td>A Dama do Amor</td>\n",
       "      <td>1PMHXEwlEv9ODnNJLPBYGP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>161453.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40266 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       danceability    energy       key  loudness      mode  speechiness  \\\n",
       "0         -0.064824  1.317150 -1.477662  0.887697 -1.344018    -0.254815   \n",
       "1          0.620469 -1.099396 -1.197239 -0.891436  0.744038     5.574823   \n",
       "2          1.007327 -0.285246 -1.477662  0.630475  0.744038    -0.439033   \n",
       "3          1.134438  0.373476 -1.477662  0.767010  0.744038    -0.426621   \n",
       "4          0.128605 -1.084593 -1.197239 -0.571346 -1.344018    -0.325367   \n",
       "...             ...       ...       ...       ...       ...          ...   \n",
       "40261      0.614942  0.432687 -0.355971  0.164445 -1.344018     0.244271   \n",
       "40262      0.686787  1.331953  0.485297  1.292600 -1.344018    -0.361949   \n",
       "40263      0.460198 -0.081708  1.046143 -0.352959 -1.344018    -0.478881   \n",
       "40264     -0.888280  1.376361  1.606988  1.690014  0.744038     1.452791   \n",
       "40265     -0.401944 -0.107613 -0.916817  0.167406  0.744038    -0.431194   \n",
       "\n",
       "       acousticness  instrumentalness  liveness   valence     tempo  \\\n",
       "0         -0.454620         -0.624436  0.406616  1.397004  1.463675   \n",
       "1          1.006105         -0.624436  2.588485  0.160478 -1.153218   \n",
       "2          1.075663         -0.623538 -0.478482  0.873430  1.197960   \n",
       "3         -0.707812         -0.620788 -0.845386  1.014535 -0.579823   \n",
       "4          0.789083         -0.624436 -0.715709 -0.493061 -0.172513   \n",
       "...             ...               ...       ...       ...       ...   \n",
       "40261     -0.635472         -0.622860 -0.571109 -0.418795 -0.679688   \n",
       "40262     -0.867518         -0.624425  0.401470  0.528094  0.257683   \n",
       "40263      0.271569         -0.424952 -0.478482  0.609786 -0.475782   \n",
       "40264     -0.387844          0.709253  0.036109 -0.972076  0.162863   \n",
       "40265      1.220345         -0.623923 -0.682775  0.357282 -1.246534   \n",
       "\n",
       "       time_signature                      artist_name  \\\n",
       "0            0.252343                          Santana   \n",
       "1           -1.818338                 Steve Hofstetter   \n",
       "2            0.252343                    Jack Hartmann   \n",
       "3            0.252343                       Tina Moore   \n",
       "4            0.252343  The American Young Voices Choir   \n",
       "...               ...                              ...   \n",
       "40261        0.252343                            Phabo   \n",
       "40262        0.252343                 Sick Individuals   \n",
       "40263        0.252343                      Marshmellow   \n",
       "40264        0.252343                              MC5   \n",
       "40265       -1.818338            Eli Silva e Zé Goiano   \n",
       "\n",
       "                                              track_name  \\\n",
       "0                        Brown Skin Girl (feat. Bo Bice)   \n",
       "1                   The Reason You Take a Date to See Me   \n",
       "2                                        We Are a Family   \n",
       "3      Never Gonna Let You Go - Kelly G. Bump-N-Go Vo...   \n",
       "4                                 Pop Medley From Trolls   \n",
       "...                                                  ...   \n",
       "40261                                          Step 2 Me   \n",
       "40262                                         I Want You   \n",
       "40263                         A Lighthouse For Your Soul   \n",
       "40264                              I’m A Man (Live 1966)   \n",
       "40265                                     A Dama do Amor   \n",
       "\n",
       "                     track_id  popularity       year      genre  duration_ms  \n",
       "0      14kZ72wYjQckHYuEvleiUx        20.0 2005-01-01      blues     282707.0  \n",
       "1      3SqfXryD4Ws7WYLEdOEYRq         8.0 2022-01-01     comedy     262360.0  \n",
       "2      5hnzpC8Fp3BzDgaacxGItd         9.0 2004-01-01      party     194320.0  \n",
       "3      0bwYKV0xuWcYviq9XJbCex        24.0 2013-01-01     garage     253080.0  \n",
       "4      3wYVbfMrSb1upgotmkIq93        24.0 2023-01-01       None     392972.0  \n",
       "...                       ...         ...        ...        ...          ...  \n",
       "40261  57tg0m3Iu8YzWyaDfFfDtR        51.0 2023-01-01      chill     110400.0  \n",
       "40262  0oZDidA985NcUVE2GhnHI1        49.0 2021-01-01        edm     186576.0  \n",
       "40263  7k74WfhigDSzIFQ9AGXiPB         0.0 2021-01-01       None     218350.0  \n",
       "40264  0eg53He31OMpYqNWmVwFAq         5.0 2008-01-01     garage     256679.0  \n",
       "40265  1PMHXEwlEv9ODnNJLPBYGP         0.0 2007-01-01  sertanejo     161453.0  \n",
       "\n",
       "[40266 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "metric_columns = [\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"time_signature\"]\n",
    "\n",
    "def standardized_data(data:pd.DataFrame):\n",
    "    standard_scaler = StandardScaler()\n",
    "    numeric_columns = data[metric_columns]\n",
    "    other_columns = data.drop(columns=metric_columns).reset_index(drop=True)\n",
    "    standardized_data = standard_scaler.fit_transform(numeric_columns)\n",
    "    standardized_df = pd.DataFrame(standardized_data, columns=numeric_columns.columns)\n",
    "    standardized_df = pd.merge(standardized_df, other_columns, left_index=True, right_index=True, how=\"left\")\n",
    "    return standardized_df\n",
    "\n",
    "def normalized_data(data:pd.DataFrame):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    numeric_columns = data[metric_columns]\n",
    "    other_columns = data.drop(columns=metric_columns).reset_index(drop=True)\n",
    "    normalized_data = min_max_scaler.fit_transform(numeric_columns)\n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=numeric_columns.columns)\n",
    "    normalized_data = pd.merge(normalized_df, other_columns, left_index=True, right_index=True)\n",
    "    return normalized_df\n",
    "\n",
    "def reduce_data(data, dimensions):\n",
    "    numeric_columns = data[metric_columns]\n",
    "    pca_standardized = PCA(n_components=dimensions)\n",
    "    pca_standardized_result = pca_standardized.fit_transform(numeric_columns)\n",
    "    return pca_standardized_result\n",
    "\n",
    "\n",
    "import hdbscan\n",
    "import joblib\n",
    "\n",
    "original_data_subset = original_data.sample(frac=0.02)\n",
    "\n",
    "original_data_subset = standardized_data(original_data_subset)\n",
    "display(original_data_subset)\n",
    "# original_data_subset = normalized_data(original_data_subset)\n",
    "# original_data_subset = reduce_data(original_data_subset, 2)\n",
    "\n",
    "data_for_clustering = original_data_subset[metric_columns]\n",
    "\n",
    "hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=10, prediction_data=True)\n",
    "hdbscan_clusterer.fit(data_for_clustering)\n",
    "joblib.dump(hdbscan_clusterer, 'hdbscan_model.pkl')\n",
    "\n",
    "clustered_subset = original_data_subset.copy()\n",
    "clustered_subset[\"cluster\"] = hdbscan_clusterer.labels_\n",
    "clustered_subset.to_parquet(\"clustered_subset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of You Ed Sheeran\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>Nathaniel Kimble</td>\n",
       "      <td>Can U Bagg It Up (Remixed)</td>\n",
       "      <td>5ZnddSlFx5cU3d5Aho3ONE</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>blues</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.761</td>\n",
       "      <td>123.955</td>\n",
       "      <td>249133.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12030</th>\n",
       "      <td>Kellie Pickler</td>\n",
       "      <td>Stop Cheatin' On Me</td>\n",
       "      <td>2Z6r4r6oqhObyU5Ftt38mP</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>country</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.352</td>\n",
       "      <td>109.608</td>\n",
       "      <td>168067.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>Cannibal Corpse</td>\n",
       "      <td>Scourge of Iron</td>\n",
       "      <td>6V3SNkvi4BnfmZU0j7s9TQ</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>death-metal</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.977</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.339</td>\n",
       "      <td>172.059</td>\n",
       "      <td>284400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22198</th>\n",
       "      <td>Raí Saia Rodada</td>\n",
       "      <td>Ponto Final - Ao Vivo</td>\n",
       "      <td>7twFGyEBkgKVT7cD28xZOk</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>forro</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.5660</td>\n",
       "      <td>0.510</td>\n",
       "      <td>176.079</td>\n",
       "      <td>216790.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22405</th>\n",
       "      <td>Stuck in the Sound</td>\n",
       "      <td>Silent and Sweet</td>\n",
       "      <td>7LROnTlpYggwagWNCdXCB1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>french</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.221</td>\n",
       "      <td>131.615</td>\n",
       "      <td>277773.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist_name                  track_name                track_id  \\\n",
       "5028     Nathaniel Kimble  Can U Bagg It Up (Remixed)  5ZnddSlFx5cU3d5Aho3ONE   \n",
       "12030      Kellie Pickler         Stop Cheatin' On Me  2Z6r4r6oqhObyU5Ftt38mP   \n",
       "13792     Cannibal Corpse             Scourge of Iron  6V3SNkvi4BnfmZU0j7s9TQ   \n",
       "22198     Raí Saia Rodada       Ponto Final - Ao Vivo  7twFGyEBkgKVT7cD28xZOk   \n",
       "22405  Stuck in the Sound            Silent and Sweet  7LROnTlpYggwagWNCdXCB1   \n",
       "\n",
       "       popularity       year        genre  danceability  energy   key  \\\n",
       "5028         16.0 2012-01-01        blues         0.876   0.415   1.0   \n",
       "12030        18.0 2012-01-01      country         0.513   0.536   2.0   \n",
       "13792        54.0 2012-01-01  death-metal         0.446   0.977  10.0   \n",
       "22198         9.0 2012-01-01        forro         0.557   0.740   0.0   \n",
       "22405        32.0 2012-01-01       french         0.508   0.765   4.0   \n",
       "\n",
       "       loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "5028     -6.795   1.0       0.0663      0.143000          0.000000    0.0639   \n",
       "12030    -5.682   1.0       0.0246      0.321000          0.000000    0.0911   \n",
       "13792    -5.036   0.0       0.0781      0.000535          0.472000    0.1050   \n",
       "22198    -6.542   1.0       0.0783      0.804000          0.000131    0.5660   \n",
       "22405    -6.020   1.0       0.0363      0.152000          0.000190    0.0995   \n",
       "\n",
       "       valence    tempo  duration_ms  time_signature  \n",
       "5028     0.761  123.955     249133.0             4.0  \n",
       "12030    0.352  109.608     168067.0             4.0  \n",
       "13792    0.339  172.059     284400.0             4.0  \n",
       "22198    0.510  176.079     216790.0             4.0  \n",
       "22405    0.221  131.615     277773.0             4.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz import process, utils\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "def get_closest_match(user_input, df, column, threshold=90):\n",
    "    processed_user_input = utils.default_process(user_input)\n",
    "    strings_column = df[column].dropna()\n",
    "    processed_strings = [utils.default_process(string) for string in strings_column]\n",
    "    \n",
    "    match = process.extractOne(processed_user_input, processed_strings, processor=None, score_cutoff=threshold)\n",
    "    if match is not None:\n",
    "        return strings_column.iloc[match[2]]  # match[2] is the index of the best match\n",
    "    return None\n",
    "\n",
    "def song_finder(song_name, artist_name):\n",
    "    song = original_data[(original_data[\"track_name\"] == song_name) & (original_data[\"artist_name\"] == artist_name)]\n",
    "    return None if song.empty else song\n",
    "\n",
    "def find_closest_songs(song_name, artist_name, same_artist, number_of_songs, data):\n",
    "    sample_data = pd.read_parquet(\"clustered_subset.parquet\")\n",
    "    metrics = [\"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \"time_signature\"]\n",
    "    \n",
    "    \n",
    "    artist_name = get_closest_match(artist_name, data, \"artist_name\")\n",
    "    song_name = get_closest_match(song_name, data, \"track_name\")\n",
    "    print(song_name, artist_name)\n",
    "    song = song_finder(song_name, artist_name)\n",
    "    \n",
    "    \n",
    "    song = standardized_data(song)\n",
    "    \n",
    "    \n",
    "    if artist_name is None or song_name is None or song is None:\n",
    "        print(\"No match found\")\n",
    "        return None\n",
    "    new_data_point = song[metrics].values.reshape(1, -1)\n",
    "    model = joblib.load('hdbscan_model.pkl')\n",
    "    predicted_cluster, _ = hdbscan.approximate_predict(model, new_data_point)\n",
    "    print(predicted_cluster[0])\n",
    "    \n",
    "    if not same_artist:\n",
    "        sample_data = sample_data[sample_data[\"artist_name\"] != artist_name]\n",
    "        \n",
    "    cluster_data = sample_data[sample_data[\"cluster\"] == predicted_cluster[0]]\n",
    "    \n",
    "    knn_model = NearestNeighbors(n_neighbors=5)\n",
    "    cluster_data = cluster_data[metrics]\n",
    "    knn_model.fit(cluster_data)\n",
    "    distances, indices = knn_model.kneighbors(song[metrics], n_neighbors=number_of_songs)\n",
    "    \n",
    "    return data[data.index.isin(cluster_data.iloc[indices[0]].index)]\n",
    "\n",
    "\n",
    "find_closest_songs(\"Shape of You\", \"Ed Sheeran\", False, 5, original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here the modelling and transformation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Select the numeric columns\n",
    "numeric_columns = feature_df.drop(columns=[\"track_id\", \"genre\"])\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Standardize the numeric columns\n",
    "standardized_data = standard_scaler.fit_transform(numeric_columns)\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=numeric_columns.columns)\n",
    "standardized_df['genre'] = feature_df['genre']\n",
    "standardized_df['track_id'] = feature_df['track_id']\n",
    "\n",
    "# Normalize the numeric columns\n",
    "normalized_data = min_max_scaler.fit_transform(numeric_columns)\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=numeric_columns.columns)\n",
    "normalized_df['genre'] = feature_df['genre']\n",
    "normalized_df['track_id'] = feature_df['track_id']\n",
    "\n",
    "# Display the standardized and normalized dataframes\n",
    "display(standardized_df.describe())\n",
    "display(normalized_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(standardized_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Perform PCA on standardized_data\n",
    "pca_standardized = PCA(n_components=2)\n",
    "pca_standardized_result = pca_standardized.fit_transform(standardized_data)\n",
    "print(1)\n",
    "\n",
    "# Perform PCA on normalized_data\n",
    "pca_normalized = PCA(n_components=2)\n",
    "pca_normalized_result = pca_normalized.fit_transform(normalized_data)\n",
    "print(2)\n",
    "\n",
    "# # Perform t-SNE on standardized_data\n",
    "# tsne_standardized = TSNE(n_components=2)\n",
    "# tsne_standardized_result = tsne_standardized.fit_transform(standardized_data)\n",
    "# print(3)\n",
    "\n",
    "# # Perform t-SNE on normalized_data\n",
    "# tsne_normalized = TSNE(n_components=2)\n",
    "# tsne_normalized_result = tsne_normalized.fit_transform(normalized_data)\n",
    "# print(4)\n",
    "\n",
    "# # Create the subplot with 4 plots\n",
    "# fig = px.subplots(\n",
    "#     rows=2, cols=2,\n",
    "#     subplot_titles=(\"PCA - Standardized Data\", \"PCA - Normalized Data\", \"t-SNE - Standardized Data\", \"t-SNE - Normalized Data\"),\n",
    "#     shared_xaxes=True, shared_yaxes=True,\n",
    "#     vertical_spacing=0.1, horizontal_spacing=0.1\n",
    "# )\n",
    "\n",
    "# # Add PCA - Standardized Data plot\n",
    "# fig.add_trace(\n",
    "#     px.scatter(x=pca_standardized_result[:, 0], y=pca_standardized_result[:, 1], color=standardized_df['track_genre']).data[0],\n",
    "#     row=1, col=1\n",
    "# )\n",
    "\n",
    "# # Add PCA - Normalized Data plot\n",
    "# fig.add_trace(\n",
    "#     px.scatter(x=pca_normalized_result[:, 0], y=pca_normalized_result[:, 1], color=normalized_df['track_genre']).data[0],\n",
    "#     row=1, col=2\n",
    "# )\n",
    "\n",
    "# # Add t-SNE - Standardized Data plot\n",
    "# fig.add_trace(\n",
    "#     px.scatter(x=tsne_standardized_result[:, 0], y=tsne_standardized_result[:, 1], color=standardized_df['track_genre']).data[0],\n",
    "#     row=2, col=1\n",
    "# )\n",
    "\n",
    "# # Add t-SNE - Normalized Data plot\n",
    "# fig.add_trace(\n",
    "#     px.scatter(x=tsne_normalized_result[:, 0], y=tsne_normalized_result[:, 1], color=normalized_df['track_genre']).data[0],\n",
    "#     row=2, col=2\n",
    "# )\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(\n",
    "#     height=800,\n",
    "#     showlegend=False\n",
    "# )\n",
    "\n",
    "# # Show the subplot\n",
    "# fig.show()\n",
    "\n",
    "px.scatter(x=pca_standardized_result[:, 0], y=pca_standardized_result[:, 1], color=standardized_df['genre']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(original_data, hue='track_genre', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "# dataframe = standardized_df.copy()\n",
    "# # Assuming 'data' is your dataframe and track_genre is a column in the dataframe\n",
    "\n",
    "# # Create a subset of the data\n",
    "# subset_data = dataframe.sample(n=1000, random_state=42)\n",
    "\n",
    "# # Prepare the data: Separate features and labels\n",
    "# features = subset_data.drop(columns=['track_genre', \"track_id\"])  # Drop the track_genre column\n",
    "# labels = subset_data['track_genre']  # Save the track_genre column separately\n",
    "\n",
    "# # Apply t-SNE\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "# # Create a DataFrame for the t-SNE results\n",
    "# tsne_df = pd.DataFrame(tsne_results, columns=['tsne_1', 'tsne_2'])\n",
    "# tsne_df['track_genre'] = labels.values\n",
    "\n",
    "# # Plot the results using Plotly Express\n",
    "# fig = px.scatter(tsne_df, x='tsne_1', y='tsne_2', color='track_genre', title='t-SNE of Track Features by Genre')\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "\n",
    "# reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "\n",
    "# # Apply UMAP\n",
    "# umap_results = reducer.fit_transform(subset_data.drop(columns=['track_genre', \"track_id\"]))\n",
    "\n",
    "# px.scatter(x=umap_results[:, 0], y=umap_results[:, 1], color=subset_data['track_genre']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from datetime import datetime\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # a function to get content-based recommendations based on music features\n",
    "# def content_based_recommendations(input_song_name, num_recommendations=5):\n",
    "#     if input_song_name not in music_df['Track Name'].values:\n",
    "#         print(f\"'{input_song_name}' not found in the dataset. Please enter a valid song name.\")\n",
    "#         return\n",
    "\n",
    "#     # Get the index of the input song in the music DataFrame\n",
    "#     input_song_index = music_df[music_df['Track Name'] == input_song_name].index[0]\n",
    "\n",
    "#     # Calculate the similarity scores based on music features (cosine similarity)\n",
    "#     similarity_scores = cosine_similarity([music_features_scaled[input_song_index]], music_features_scaled)\n",
    "\n",
    "#     # Get the indices of the most similar songs\n",
    "#     similar_song_indices = similarity_scores.argsort()[0][::-1][1:num_recommendations + 1]\n",
    "\n",
    "#     # Get the names of the most similar songs based on content-based filtering\n",
    "#     content_based_recommendations = music_df.iloc[similar_song_indices][['Track Name', 'Artists', 'Album Name', 'Release Date', 'Popularity']]\n",
    "\n",
    "#     return content_based_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Loop through a range of cluster numbers to calculate silhouette scores\n",
    "silhouette_scores = []\n",
    "cluster_range = range(2, 26)\n",
    "data_sample = standardized_data[np.random.choice(standardized_data.shape[0], 20000, replace=False)]\n",
    "for k in cluster_range:\n",
    "    print(f\"Calculating silhouette score for k = {k}\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(data_sample)\n",
    "    silhouette_avg = silhouette_score(data_sample, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {k}, the average silhouette score is {silhouette_avg:.4f}\")\n",
    "\n",
    "# Optionally, you can plot the silhouette scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Scores for k-means clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import HDBSCAN\n",
    "\n",
    "data_sample = standardized_data[np.random.choice(standardized_data.shape[0], 200000, replace=False)]\n",
    "\n",
    "# Fit the HDBSCAN model\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=100)\n",
    "hdbscan_model.fit(data_sample)\n",
    "\n",
    "# Get the labels assigned to each data point\n",
    "cluster_labels = hdbscan_model.labels_\n",
    "\n",
    "# Example: Print out the first 10 cluster labels\n",
    "print(\"First 10 cluster labels:\", cluster_labels[:10])\n",
    "\n",
    "# Print out the number of clusters found (excluding noise)\n",
    "print(f\"Number of clusters found: {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_finder(song_name, artist_name):\n",
    "    song = original_data[(original_data[\"track_name\"] == song_name) & (original_data[\"artist_name\"] == artist_name)]\n",
    "    return song\n",
    "\n",
    "song = song_finder(\"Shape of You\", \"Ed Sheeran\")\n",
    "\n",
    "standardized_data[song.index]\n",
    "\n",
    "for song in original_data[['track_name', 'artist_name']].itertuples():\n",
    "    print(song[0])\n",
    "    print(standardized_data[song[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def song_finder(song_name, artist_name):\n",
    "    song = original_data[(original_data[\"track_name\"] == song_name) & (original_data[\"artist_name\"] == artist_name)]\n",
    "    return song\n",
    "\n",
    "def find_closest_songs(song_name, artist_name, song_number=5):\n",
    "    all_distances = []\n",
    "    \n",
    "    chosen_song = song_finder(song_name, artist_name)\n",
    "    index = chosen_song.index\n",
    "    print(index)\n",
    "    print(standardized_data[index][0])\n",
    "    for song in original_data[['track_name', 'artist_name']].itertuples():\n",
    "\n",
    "        current_distance = distance.cosine(standardized_data[song[0]],standardized_data[chosen_song.index][0])\n",
    "        all_distances.append((song.track_name, song.artist_name, current_distance))\n",
    "    all_distances.sort(key=lambda x: x[2], reverse=False)\n",
    "    return all_distances[1:song_number+1]\n",
    "\n",
    "find_closest_songs(\"Shape of You\", \"Skrillex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
